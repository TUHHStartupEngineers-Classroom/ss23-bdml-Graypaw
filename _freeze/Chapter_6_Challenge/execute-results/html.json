{
  "hash": "11ad57da9d9ecb7f619d5545736323d9",
  "result": {
    "markdown": "Libraries\n\n::: {.cell hash='Chapter_6_Challenge_cache/html/unnamed-chunk-1_0b0275e31fab270dbb7e2e2b4f0174f6'}\n\n```{.r .cell-code}\nlibrary(h2o)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n----------------------------------------------------------------------\n\nYour next step is to start H2O:\n    > h2o.init()\n\nFor H2O package documentation, ask for help:\n    > ??h2o\n\nAfter starting H2O, you can use the Web UI at http://localhost:54321\nFor more information visit https://docs.h2o.ai\n\n----------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttache Paket: 'h2o'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nDie folgenden Objekte sind maskiert von 'package:stats':\n\n    cor, sd, var\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nDie folgenden Objekte sind maskiert von 'package:base':\n\n    %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n    colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n    log10, log1p, log2, round, signif, trunc\n```\n:::\n\n```{.r .cell-code}\nlibrary(recipes)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLade nötiges Paket: dplyr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttache Paket: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nDie folgenden Objekte sind maskiert von 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nDie folgenden Objekte sind maskiert von 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttache Paket: 'recipes'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nDas folgende Objekt ist maskiert 'package:stats':\n\n    step\n```\n:::\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.4\n✔ ggplot2   3.4.2     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ lubridate::day()   masks h2o::day()\n✖ dplyr::filter()    masks stats::filter()\n✖ stringr::fixed()   masks recipes::fixed()\n✖ lubridate::hour()  masks h2o::hour()\n✖ dplyr::lag()       masks stats::lag()\n✖ lubridate::month() masks h2o::month()\n✖ lubridate::week()  masks h2o::week()\n✖ lubridate::year()  masks h2o::year()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyquant)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLade nötiges Paket: PerformanceAnalytics\nLade nötiges Paket: xts\nLade nötiges Paket: zoo\n\nAttache Paket: 'zoo'\n\nDie folgenden Objekte sind maskiert von 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\nAttache Paket: 'xts'\n\nDie folgenden Objekte sind maskiert von 'package:dplyr':\n\n    first, last\n\n\nAttache Paket: 'PerformanceAnalytics'\n\nDas folgende Objekt ist maskiert 'package:graphics':\n\n    legend\n\nLade nötiges Paket: quantmod\nLade nötiges Paket: TTR\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n```\n:::\n\n```{.r .cell-code}\nlibrary(lime)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttache Paket: 'lime'\n\nDas folgende Objekt ist maskiert 'package:dplyr':\n\n    explain\n```\n:::\n:::\n\n\nPlot_Features function\n\n::: {.cell hash='Chapter_6_Challenge_cache/html/unnamed-chunk-2_9a072fc7cd502a59c796293b3e3e36f2'}\n\n```{.r .cell-code}\nplot_features <- function(data) {\n  numeric_cols <- sapply(data, is.numeric)\n  \n  # Compute the mean importance across rows\n  mean_importance <- colMeans(data[, numeric_cols, drop = FALSE])\n\n  # Create a data frame for plotting\n  plot_data <- data.frame(\n    Feature = colnames(data)[numeric_cols],\n    Importance = mean_importance\n  )\n\n  # Sort the features by importance\n  plot_data <- plot_data[order(plot_data$Importance, decreasing = TRUE), ]\n\n  # Plot the feature importance using ggplot\n  ggplot(data = plot_data, aes(x = reorder(Feature, Importance), y = Importance)) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\") +\n    xlab(\"Feature\") +\n    ylab(\"Importance\") +\n    ggtitle(\"Feature Importance\") +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n}\n```\n:::\n\n::: {.cell hash='Chapter_6_Challenge_cache/html/unnamed-chunk-3_3620316dcc5bf0030f1b82f2470c724e'}\n\n```{.r .cell-code}\ndataset <- read.csv(\"product_backorders.csv\")\n\ndata_recipe <- recipe(went_on_backorder ~ ., data = dataset) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_zv(all_predictors()) %>%\n  step_normalize(all_predictors()) %>%\n  prep()\n\nprepared_data <- bake(data_recipe, new_data = dataset)\n\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         18 minutes 4 seconds \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.40.0.4 \n    H2O cluster version age:    1 month and 17 days \n    H2O cluster name:           H2O_started_from_R_jakbo_whs664 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   3.15 GB \n    H2O cluster total cores:    8 \n    H2O cluster allowed cores:  8 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.3.0 (2023-04-21 ucrt) \n```\n:::\n\n```{.r .cell-code}\nsplit_h2o <- h2o.splitFrame(as.h2o(prepared_data), ratios = c(0.85))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\n\nautoml_leader <- h2o.loadModel(\"leadermodel_h2o\\\\StackedEnsemble_AllModels_4_AutoML_11_20230615_00001\")\n\nexplainer <- as_tibble(train_h2o) %>%\n    select(-went_on_backorder) %>%\n    lime(\n        model           = automl_leader,\n        bin_continuous  = TRUE,\n        n_bins          = 4,\n        quantile_bins   = TRUE\n    )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: in_transit_qty does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: pieces_past_due does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: local_bo_qty does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: potential_issue_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: deck_risk_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: oe_constraint_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: ppap_risk_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: stop_auto_buy_Yes does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: rev_stop_Yes does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n```\n:::\n:::\n\n::: {.cell hash='Chapter_6_Challenge_cache/html/unnamed-chunk-4_337f43a61b5918aa0ab56e1d5365b785'}\n\n```{.r .cell-code}\nexplanation <- as_tibble(valid_h2o) %>%\n    slice(1) %>%\n    select(-went_on_backorder) %>%\n    lime::explain(\n    \n        # Pass our explainer object\n        explainer = explainer,\n        # Because it is a binary classification model: 1\n        n_labels   = 1,\n        # number of features to be returned\n        n_features = 8,\n        # number of localized linear models\n        n_permutations = 5000,\n        # Let's start with 1\n        kernel_width   = 1\n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n:::\n\n::: {.cell hash='Chapter_6_Challenge_cache/html/unnamed-chunk-5_4e08c094e28556c0c694b766b970e98b'}\n\n```{.r .cell-code}\nexplanation %>% \n  as.tibble()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 13\n  model_type    case  label label_prob model_r2 model_intercept model_prediction\n  <chr>         <chr> <chr>      <dbl>    <dbl>           <dbl>            <dbl>\n1 classificati… 1     No         0.650    0.339           0.805            0.651\n2 classificati… 1     No         0.650    0.339           0.805            0.651\n3 classificati… 1     No         0.650    0.339           0.805            0.651\n4 classificati… 1     No         0.650    0.339           0.805            0.651\n5 classificati… 1     No         0.650    0.339           0.805            0.651\n6 classificati… 1     No         0.650    0.339           0.805            0.651\n7 classificati… 1     No         0.650    0.339           0.805            0.651\n8 classificati… 1     No         0.650    0.339           0.805            0.651\n# ℹ 6 more variables: feature <chr>, feature_value <dbl>, feature_weight <dbl>,\n#   feature_desc <chr>, data <list>, prediction <list>\n```\n:::\n\n```{.r .cell-code}\ncase_1 <- explanation %>%\n    filter(case == 1)\n\ncase_1 %>%\n    plot_features()\n```\n\n::: {.cell-output-display}\n![](Chapter_6_Challenge_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nOther function\n\n::: {.cell hash='Chapter_6_Challenge_cache/html/unnamed-chunk-6_fcd06af6e4598155fb162f8b73fa5a65'}\n\n```{.r .cell-code}\nplot_explanations <- function(data) {\n  # Convert non-numeric columns to factors\n  non_numeric_cols <- sapply(data, function(x) !is.numeric(x))\n  data[, non_numeric_cols] <- lapply(data[, non_numeric_cols], as.factor)\n\n  # Convert data to long format\n  data_long <- tidyr::gather(data, key = \"Feature\", value = \"Importance\")\n\n  # Plot the explanations using ggplot\n  ggplot(data = data_long, aes(x = Feature, y = as.numeric(factor(1)), fill = Importance)) +\n    geom_tile() +\n    xlab(\"Feature\") +\n    ylab(\"\") +\n    ggtitle(\"Feature Importances\") +\n    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1),\n          panel.grid.major = element_blank(),\n          panel.grid.minor = element_blank()) +\n    facet_wrap(~ Feature, scales = \"free\", ncol = 2)\n}\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}